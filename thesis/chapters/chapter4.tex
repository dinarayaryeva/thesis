\chapter{Methodology}
\label{chap:ctrl}

\chaptermark{Forth Chapter Heading}

    The development of a robust control system for underwater robots hinges on a 
    comprehensive understanding of system dynamics and control objectives.
    This chapter explores control design for underwater robots, focusing on the application 
    of sliding mode control to address challenges in marine environments. By integrating 
    robust control strategies, the aim is to enhance the stability, accuracy, and 
    responsiveness of underwater robotic systems operating in dynamic and unpredictable conditions.

\section{Design Considerations}

    This section provides an introduction to control systems, starting with defining objectives 
    that serve as a foundation for understanding subsequent topics.

    \subsection{Control Objectives}

    The main idea of the control system design is to choose such control input $u$ which 
    meets the desired performance specifications while ensuring stability.

    Underwater robots require precise control systems to navigate and operate effectively
    in challenging marine environments. These control objectives are crucial for ensuring
    the robot's stability, accuracy, and responsiveness:
    \begin{itemize}
        \item Position and Orientation Tracking:
            The robot must accurately follow a desired trajectory, maintaining its position
            and orientation as intended.
        \item Disturbance Rejection:
            The robot should be able to withstand external disturbances, such as ocean
            currents, waves, and sensor noise, to maintain stable tracking performance.
        \item Robustness:
            The control system should be robust to uncertainties in the robot's dynamics
            and environmental conditions, ensuring reliable operation even in unpredictable
            situations.
        \item Real-Time Implementation:
            The control algorithm should be computationally efficient and able to run in
            real-time on the robot's embedded system, enabling prompt and effective
            responses to changing conditions.
    \end{itemize}

    Next, let us discuss the challenges posed by uncertainties in control system modeling, 
    which must be understood before diving into advanced control techniques.

\subsection{Model Uncertainties}

    The estimated model dynamics may not perfectly match the actual system behavior 
    due to imprecise parameter estimates caused by simplified dynamics 
    and external factors. Two primary types of modeling inaccuracies 
    are defined by J. Slotine and W. Li \cite{slotine_applied}:
    \begin{enumerate}
        \item Structured (or parametric) uncertainties : 
        associated with errors in the terms included in the model
        \item Unstructured uncertainties (or unmodeled dynamics) : 
        linked to inaccuracies in the system's order
    \end{enumerate}

    Recalling dynamics of ROV, following parameters may have some imprecision:
    \begin{itemize}
        \item \textbf{Body parameters}. The mass matrix $M_B$ and the matrix of Coriolis forces $C_B$ 
        may unknown due to uncertain values of mass $m$ and inertia matrix $I_0$.
        \item Coefficients of \textbf{viscous damping} $D$. The values for linear and quadratic 
        terms are defined empirically.
        \item \textbf{Restoring forces} $g$. Specifically, water density $\rho$ is environment dependent 
        and whole body volume $\nabla$ is hard to calculate with proper accuracy.
        \item \textbf{Added mass parameters} $M_A$ and $C_A$. They cannot be calculated directly and will 
        be excluded in future calculations.
    \end{itemize}
    Further, the approximated value of the parameter $x$ is represented as $\mathbf{\hat x}$,
    while the difference between this approximation and the actual value is 
    defined as $\mathbf{\tilde x = \hat x - x}$. Instead of the omitted terms, we will incorporate a common disturbance 
    term $\delta$.

    In this way, the dynamics in equation \ref{eq::matrix_dynamics} takes the following form:
    \begin{equation}
        M_B \dot{\bar{v}}^B + C_B(\bar{v}^B) \bar{v}^B+D(\bar{v}^B) \bar{v}^B+g(\bar{r}^N)
            + \delta = T\phi(u)
    \end{equation}

\subsection{Thruster Mapping Approximation}
    As stated before, thruster mapping is defined through the configuration 
    matrix $T$ and the DC-gain transfer function $\phi(u)$. However, $\phi(u)$ 
    can be highly nonlinear and voltage dependent. 
    Let us examine the general function $\phi(u)$ shown in Fig. \ref{image:thrust}.
    \begin{figure}[H]
        \centering\includegraphics*[width=0.5\textwidth]{thrust_plot}
        \caption{Relationship Between Thrust Output and Pulse Width Modulation (PWM) Signal for ROV Thrusters}
        \label{image:thrust}
    \end{figure}
    It is suggested to use a third-order polynomial to model the transfer function above. 
    This approach is deemed suitable due to the general shape of the PWM to thrust relation.
    
    The approximated function is expressed as 
    \begin{equation}
        \hat{\phi}(u) = k\phi_0(u)   
    \end{equation}
    \begin{conditions}
        \text{\quad}k & the scaling coefficient\\
        \phi_0(u) & the nominal third-order polynomial
    \end{conditions} 
    \vspace{0.5cm}

    The value of $k$ must be between $k_{min} = 0.4$ and $k_{max} = 1$ to cover the 
    entire range.
    (Fig. \ref{image:thrust_apprx}).
    \begin{figure}[H]
        \centering\includegraphics*[width=0.5\textwidth]{apprx}
        \caption{Approximation Model for Thruster Mapping in ROV Control Systems}
        \label{image:thrust_apprx}
    \end{figure}
    
    Thus, the thruster mapping takes the form:
    \begin{equation}
        \hat{\bar{f}}^B=T\hat{\phi}(u) = kT\phi_0(u) = B\phi_0(u)
    \end{equation}

    \subsection{Approximated System Dynamics}
    By taking into account the impact of both dynamic approximations 
    and disturbances, we can obtain the following dynamics of the 
    system:
    \begin{equation}
        M_B \dot{\bar{v}}^B + C_B(\bar{v}^B) \bar{v}^B+D(\bar{v}^B) \bar{v}^B+g(\bar{r}^N)
         + \delta = B\phi_0(u)
    \end{equation}
    
    For the sake of simplicity, we omit some redundant notations: $*_B$, $\bar *$, $*^B$ and $*^N$. 
    However, the meaning behind these notations remains valid, 
    whereas the formulas become more comprehensible.

    Additionally, let us describe the internal and external forces acting on the 
    body using the single nonlinear term $h(r,v)$:
    \begin{equation}
        h(r,v) = C(v)v + D(v)v + g(r)
    \end{equation}
    Finally, the approximated system dynamics equation is defined as:
    \begin{equation}
        M \dot{v} + h(r, v) + \delta = B\phi_0(u)
        \label{eqn::apprx_dynamics}
    \end{equation}

\subsection{Summary}
    To summarize, the main objective of the underwater control system is to accurately 
    follow the desired trajectory, even in the presence of external disturbances 
    and uncertainties. The ultimate goal is to make sure that the tracking error 
    approaches zero as time progresses towards infinity.

    As was previously mentioned, control systems can be negatively impacted 
    by modeling nonlinear dynamics. Therefore, any practical design must handle them explicitly. 
    Inverse dynamics control can be a good starting point for deriving complex nonlinear 
    control approaches, as it addresses the nonlinearities present in the system.

\section{Inverse dynamics}

    The nonlinear control method, known as inverse dynamics, tracks a trajectory by calculating the joint actuator torques required to achieve a specific trajectory. This approach relies on exact cancellation of nonlinearities in the robot equation of motion.

    The concept of inverse dynamics control is closely linked to solving the inverse dynamics problem. By appropriately inverting the dynamic model, a control law can effectively cancel out the nonlinear dynamics, isolate the interactions between the controlled variables, and specify the time characteristics of the decay of task errors

    \subsection{Virtual Control}
    To simplify the control process, we can define a virtual control
    input $\boldsymbol{\nu}$, which is related to the actual control input $\mathbf{u}$ 
    as:
    \begin{equation}
        \nu = \phi_0(u)
    \end{equation} 
    It is important to note that there exists an inverse relation between 
    the actual control input and the virtual control input, namely 
    $u = \phi_0^{-1}(\nu)$. 
    This inverse relation will allow us to easily switch back and forth 
    between the actual and virtual control inputs as needed.

    \subsection{Control Law Design}
      Recalling the approximated dynamics equation \ref{eqn::apprx_dynamics}, we can design the following virtual control law to 
    linearize the system:
    \begin{equation}
        \label{eqn::inverse_dynamics}
        \nu = B^{+} (Ma + h(r, v))
    \end{equation}
    while the outer-loop control $a$ is designed as a proportional-derivative (PD) controller:
    \begin{equation}
        a = \dot{v}_{des} - K_p \tilde{r} - K_d \tilde{v}
    \end{equation}

    The equation \ref{eqn::inverse_dynamics} becomes more complex when system parameters and disturbances are 
    unknown:
    \begin{equation}
    \nu = \hat{B}^{+}(\hat{M}a + \hat h(r, v))
    \end{equation}
    Substitution to the dynamics yields:
    \begin{equation}
    \dot{v} = M^{-1}(B\hat{B}^{+}h(r, v) - \hat h(r, v) - \delta) + 
    M^{-1}B\hat{B}^{+}\hat{M}a
    \end{equation}

    \subsection{Error Analysis}
    In terms of tracking error $e = \tilde{r}$, we can design the following system:
    \begin{equation}
        \begin{aligned}
        e &= \tilde{r} \\
        \dot{e} &= \tilde{v} \\
        \ddot{e} &= \dot{\tilde{v}} =\\
        &= \dot{v}_{des} - \dot{v} =\\
        &= \dot{v}_{des} - M^{-1}(B\hat{B}^{+}h - \hat{h} - \delta) + M^{-1}B\hat{B}^{+}\hat{M}(\dot{v}_{des} - K_pe - K_d \dot{e})
        \end{aligned}
        \end{equation}
    Hence, the error dynamics can be represented in the form of a second-order differential equation as:
    \begin{equation}
    \begin{aligned}
        \ddot e + A_1 \dot e + A_0 e  &= (W-I)\dot{v}_{des}
        - M^{-1}(B\hat{B}^{+}h - \hat h - \delta) =\\
        &=d(e, \dot{e}, \dot{v}_{des})
    \end{aligned}
    \end{equation}
    with $W = M^{-1}B\hat{B}^{+}\hat{M}$, $A_0 = WK_p$ and $A_1 = WK_d$.

    In state-space form, we can express the error dynamics as:
    \begin{equation}
        \dot{x} = Ax + Bd
    \end{equation}
    where
    \[
    x = \begin{bmatrix} e \\ \dot{e} \end{bmatrix}, \quad
    A = \begin{bmatrix} 0_{6 \times 6} & I_{6 \times 6} \\ -A_0 & -A_1 \end{bmatrix}, \quad
    B = \begin{bmatrix} 0_{6 \times 6} \\ I_{6 \times 6} \end{bmatrix}
    \]
    The analytical solution of the state-space equation is given by:
    \begin{equation}
        x(t) = e^{At}x(0) + \int_0^t e^{A(t - \tau)}Bd(\tau) \, d\tau
    \end{equation}
    To find the bounds on the error, we assume that \( (e, \dot{e}, \dot{v}_{des}) \) is bounded, i.e., \( \|d\| \leq D \), and derive:
    \begin{equation}
        \|x(t)\| \leq C e^{-\alpha t} \|x(0)\| + \int_0^t C e^{-\alpha (t - \tau)} \|B\| D \, d\tau
    \end{equation}
    Evaluating the integral, we get:
    \begin{equation}
        \|x(t)\| \leq C e^{-\alpha t} \|x(0)\| + \|B\| D C \left[ \frac{1 - e^{-\alpha t}}{\alpha} \right]
    \end{equation}
    As \( t \to \infty \), the exponential terms decay to zero, and we get:
    \begin{equation}
        \|x(t)\| \leq \frac{C \|B\| D}{\alpha}
    \end{equation}
    Since \( x = \begin{bmatrix} e \\ \dot{e} \end{bmatrix} \), the error \( e \) is bounded by:
    \begin{equation}
        \|e\| \leq \frac{\|d\|}{\lambda_{min}(A_0)}
    \end{equation}
    where $\lambda_{min}(A_0)$ is the minimum eigenvalue of $A_0$.
    
    \subsection{Summary}
    The inverse dynamics technique, while effective in theory, presents several challenges in practical applications:
    \begin{itemize}
        \item \textbf{Undefined or Large Error Bounds}: The error bounds can be large or undefined if $\dot{v}_{des}$ is not properly bounded.
        \item \textbf{Difficulty in Tuning}: The parameters $K_p$ and $K_d$ require careful tuning to achieve desired performance.
        \item \textbf{Lack of Robustness}: The method is not robust to parameter uncertainties and external disturbances.
    \end{itemize}

    As a result, the inverse dynamics technique may not be the best option for effectively 
    controlling underwater systems. Further we introduce sliding mode control, which is a robust 
    control technique that can achieve desired control objectives in the presence of uncertainties.

\section{Sliding Mode}

    As discussed before, there are several robust controller
    designs available. However, the sliding mode approach, suggested by Vadim 
    Utkin in the late 1970s, is highly regarded as the most sophisticated and 
    frequently implemented one \cite{utkin}.

    Sliding mode control (SMC) is a nonlinear control method that guarantees
    robust control of systems with uncertainties and disturbances.
    This technique involves developing a sliding surface within the state
    space and directing the system's trajectory to slide along this surface (Fig. \ref{image:sliding_mode}).
    
    Compared to other nonlinear control methods, SMC is a relatively straightforward
    solution to implement with a basic understanding of system dynamics and sliding
    surface design. SMC provides a fast transient response due to the sliding dynamics, which makes 
    it possible to track desired references or trajectories quickly.

    \begin{figure}[H]
        \centering\includegraphics*[width=0.7\textwidth]{smc}
        \caption{General Schematic of Sliding Mode Control (SMC). Adopted from \cite{img_smc}}
        \label{image:sliding_mode}
    \end{figure}

\subsection{Sliding Surface Design}

    In sliding mode control, a sliding surface is a hyperplane in
    the state space that defines the desired system behavior.
    The aim of the control is to force the system's trajectory to slide
    along this surface. As long as the control law is in effect, 
    the system's trajectory will stay on the sliding surface once it reaches it (Fig. \ref{image:sliding_phases}).

    \begin{figure}[H]
        \centering\includegraphics*[width=0.8\textwidth]{sliding_phases}
        \caption{Phases of Sliding Mode Control: Reaching Phase and Sliding Phase. Adopted from \cite{smc_phases}}
        \label{image:sliding_phases}
    \end{figure}

    The design of the sliding surface is critical for the performance of the SMC
    system. The sliding surface should be:
    \begin{itemize}
        \item Reachable: The system's trajectory should be able to reach the sliding
            surface in a finite amount of time.
        \item Invariant: The system will stay on the sliding surface as long as the 
        control law is in effect once its trajectory reaches it.
        \item Attractive: The control law should attract the system's trajectory to the
            sliding surface and keep it there.
    \end{itemize}

    In order to satisfy the conditions above, the sliding surface is designed to be an invariant set.
    Invariant sets are sets of states in the state space that, once entered, cannot be exited under 
    the action of the control law.

    \subsection{Sliding Condition}
    In the state space $\mathbb{R}^n$, let us define the time-varying surface
    given by scalar equation $\mathbf{s(r, t)}$:
    \begin{equation}
        \mathbf{s(r, t)} = (\frac{d}{dt} + \lambda)^{n-1}\tilde{{r}}
    \end{equation}
    where $n$ denotes the system's order and $\lambda$ is a positive scalar.

    In order to ensure convergence of $\mathbf{s(r, t)}$ along all system trajectories in finite time, 
    let us define Lyapunov candidate $\mathbf{V = s^2}$ as the squared distance to the surface.
    
    The sliding condition can then be formulated accordingly:
    \begin{equation}
    \frac{dV}{dt} < -\eta \sqrt{V} \text{\quad or \quad}
    \frac{1}{2}\frac{d}{dt}\|s\|^2 = s^T\dot{s} < -\eta \|s\|
    \label{eq::sliding}
    \end{equation}
    where $\eta>0$ defines the rate of convergence to the sliding surface.

    When the sliding condition is satisfied, the surface becomes an invariant set
    and implies convergence to $\mathbf{\tilde{r}}$, since the system described by 
    the differential equation:
    \begin{equation}
        s = (\frac{d}{dt} + \lambda)^{n-1}\tilde r = 0
    \end{equation}
    is inherently stable and remains at the equilibrium point $\mathbf{\tilde{r} = 0}$.

    Applying such transformation yields a new representation of the tracking performance:
    \begin{equation}
        s \rightarrow 0 \Rightarrow \tilde{r} \rightarrow 0
    \end{equation}
    In other words, tracking $\mathbf{r}$ is the same as staying on the sliding surface. 
    It is thus possible to replace the tracking problem of the $n$-dimensional vector 
    $\mathbf{r}$ with a first order stabilization problem in $\mathbf{s}$.

\subsection{Control Law Design}

    The control input $\mathbf{a}$ comprises two distinct components: 
    nominal control $\mathbf{a_n}$, 
    and an additional robust part $\mathbf{a_s}$: 
    \begin{equation}
        a = a_n + a_s
    \end{equation}
    \begin{figure}[H]
        \centering\includegraphics*[width=0.8\textwidth]{control_scheme}
        \caption{Control Scheme for Sliding Mode Control (SMC) in ROVs}
        \label{image:control_scheme}
    \end{figure}
    The nominal control $\mathbf{a_n}$ aims to compensate for the system's dynamics, 
    while the robustifying component $\mathbf{a_s}$ is designed to enhance the 
    controller's stability and performance by providing additional corrective 
    action to counteract uncertainties and disturbances.

    To simplify computations, we can use a virtual force $f_v$:
    \begin{equation}
        f_v = T\nu
    \end{equation}
    which can represent the desired behavior of the system without introducing input uncertainty.

    Using the inverse dynamics approach \ref{eqn::inverse_dynamics}, we can apply the outer loop 
    controller to partially linearize the system with model estimates:
    \begin{equation}
        \hat{f} = \hat{k}f_v = \hat{M}a + \hat{h}(r, v)
    \end{equation}
    Expressing virtual control input, we obtain:
    \begin{equation}
    f_v = \frac{\hat{M}a + \hat{h}(r, v)}{\hat{k}}
    \end{equation}
    Substitution to the dynamics \ref{eqn::apprx_dynamics} yields the equation:
    \begin{equation}
        \begin{aligned}
        \dot{v} &= \underbrace{M^{-1}(\frac{k}{\hat{k}}\hat{h}(r, v) - h(r, v)
         - \delta)}_{F(r, v)} + \underbrace{\frac{k}{\hat{k}}M^{-1}\hat{M}}_{K}a = \\
        &= F(r, v) + Ka
        \end{aligned}
    \end{equation}
    where the terms $F(r,v)$ and $K$ represent dynamical and inertial uncertainties.

    The time derivative of $\mathbf{s}$ is connected to dynamics as follows:
    \begin{equation}
    \dot{s} = \dot{\tilde{v}} + \lambda \tilde{v} = 
    a_n - \dot{v} = a_n - F - K(a_n + a_s) = w - Ka_s 
    \end{equation}
    with error function $w(r, v) = (I - K)a_n - F(r, v) $

    Substitution to sliding condition \ref{eq::sliding} yields:
    \begin{equation}
    s^Tw- s^TKa_s  \leq \|s\|\|w\| - s^TKa_s  \leq - \eta \|s\|
    \label{eqn::sliding_condition}
    \end{equation}

    Let us recall that for any symmetric matrix P:
    \begin{equation}
        \label{eqn:property}
        \sigma^2_{min} \|x\|^2 \leq \|x^TPx\| \leq \sigma^2_{max} \|x\|^2
    \end{equation}
    with $\sigma_{min}$ and $\sigma_{max}$ being the largest and smallest 
    eigenvalues of matrix P.

    Thus, we can use property \ref*{eqn:property} to choose the stabilizing control 
    $\mathbf{a_s}$ as:
    \begin{equation}
        a_s = \frac{\alpha \hat{k}}{\sigma_{min}^2}\hat{M}^{-1}\frac{s}{\|s\|} = 
        \rho \frac{s}{\|s\|} 
    \end{equation}
    where $\sigma_{min}$ is minimal singular value of $M^{-1}$
    which provide:
    \begin{equation}
        \|s\|\|w\| - s^TKa_s \leq 
        \|s\|\|w\| - k \frac{\alpha}{\sigma^2_{min}\|s\|}s^TM^{-1}s \leq 
        \|s\|\|w\| - \alpha k \|s\|
    \end{equation}
    but by definition $k_{min} < k < k_{max}$, therefore
    \begin{equation}
        \|s\|\|w\| - \alpha k \|s\| \leq
        \|s\|\|w\| - \alpha k_{min} \|s\| < - \eta \|s\|
    \end{equation}
    Setting gain $\alpha$ accordingly to:
    \begin{equation}
    \alpha > \frac{\|w\| + \eta}{k_{min}}
    \end{equation}
    will satisfy sliding conditions.

    The final expression for sliding control:
    \begin{equation}   
    a_s = 
    \begin{cases}
    \rho \frac{s}{\|s\|}, \quad \|s\| > 0\\
    0, \quad \|s\| = 0 
    \end{cases}
    \end{equation}

    In order to reduce chattering, the controller above is effectively smoothed using
    the boundary layer:
    \begin{equation}
    a_s = 
    \begin{cases}
    \rho \frac{s}{\|s\|}, \quad \|s\| >\epsilon\\
    \rho \frac{s}{\epsilon}, \quad \|s\| \leq\epsilon
    \end{cases}
    \end{equation}
    where $\epsilon$ is the boundary layer thickness.

    \begin{figure}[H]
        \centering\includegraphics*[width=0.6\textwidth]{boundary}
        \caption{Sliding Mode Control Scheme with the Addition of a Boundary Layer to Reduce Chattering. Adopted from \cite{boundary}}
        \label{image:boundary}
    \end{figure}

    The nominal control $a_n$ can be 
    designed in a form of PD controller:
    \begin{equation}
        a_n = - K_p\tilde{r}^B - K_d\tilde{v}^B
    \end{equation}

    The resulting controller is then given as follows:
    \begin{align} 
        &\nu = \hat{B}^{+}(\hat{M}(a_n + a_s) + \hat h(r, v))
        \label{eqn::sliding_mode} \\
        &a_n = - K_p\tilde{r} - K_d\tilde{v} \\
        &s = \tilde{v} + \lambda \tilde{r} \\
        &a_s = 
        \begin{cases}
        \rho \frac{s}{\|s\|}, \quad \|s\| >\epsilon\\
        \rho \frac{s}{\epsilon}, \quad \|s\| \leq\epsilon
        \end{cases}
    \end{align}

    \subsection{Summary}

    Although sliding mode control has proven to be an effective approach, there are certain drawbacks associated with its use:
    \begin{itemize}
        \item \textbf{Chattering}: The control signal can exhibit high-frequency oscillations, potentially causing wear and noise in mechanical systems.
        \item \textbf{Discontinuous Control}: The abrupt switching in the control action can be challenging to implement and may affect actuator performance.
        \item \textbf{Complex Fine-Tuning}: Designing and adjusting the control parameters can be complex and requires expertise.
        \item \textbf{Unlimited Control Input}: The method does not inherently limit the control input, which can result in excessively high control efforts.
    \end{itemize}
    Nevertheless, ongoing advancements in control theory and implementation techniques are serving to enhance the value of this method for a range of engineering applications.
        
    While sliding mode control offers robustness in many scenarios, 
    optimization-based control approaches provide an alternative avenue 
    for addressing some of its limitations.

\section{Optimization-based control}

    Optimization-based control is a highly promising solution 
    for complex control problems, as it endeavors to discover 
    optimal control inputs that fulfill desired performance 
    criteria while also taking system constraints into account. 

    In modern engineering applications, the pursuit of flexible and versatile 
    control solutions necessitates the use of optimization techniques. These 
    techniques serve to optimize system performance, incorporate constraints 
    and objectives, and facilitate precise tuning and adaptation within complex systems.

    \subsection{Optimization problem}

    Convex optimization involves minimizing a convex objective function over a convex set. 
    Quadratic Programming (QP) is a special type of convex optimization where the objective 
    function is quadratic, and the constraints are linear.

    The standard form of a Quadratic Programming problem is given by:
    \begin{equation}
    \begin{aligned}
    & \underset{x \in R^n}{\text{minimize}}
    & & \frac{1}{2} x^T Q x + c^T x \\
    & \text{subject to}
    & & A x \leq b, \\
    & & & E x = d,
    \end{aligned}
    \end{equation}
    \begin{conditions}
        x & is the vector of variables to be optimized; \\
        Q & is a symmetric positive semidefinite 
        matrix;\\
        c & is a vector of linear coefficients;\\
        A, b & coefficients and bounds of the inequality constraints; \\
        E, d & coefficients and right-hand side of the equality constraints.
    \end{conditions}
    \vspace{0.5cm}
    The above formulation sets the stage for applying optimization-based control techniques to practical problems.

    \subsection{Control Law Design}

    The core of optimization-based control lies in formulating and solving optimization 
    problems for to the specific dynamics and constraints of the system. 
    Recalling a sliding mode controller \ref{eqn::sliding_mode}:
    \begin{equation*}
        \hat M(a_n + a_s)  + \hat h (r, v) = \hat B \nu
    \end{equation*}
    This equation represents the controller dynamics, where $\hat{M}$, $\hat{h}$, 
    and $\hat{B}$ are approximated system matrices, $a_n$ represents nominal control inputs, 
    $a_s$ denotes the sliding mode control inputs, and $\nu$ represents the virtual control input.

    In sliding mode control, a key condition, known as the sliding condition, 
    ensures the system trajectories converge to a specified surface. 
    Mathematically, this condition can be represented as \ref{eqn::sliding_condition}:
    \begin{equation*}
        s^TKa_s \geq \eta \|s\| + \|s\|\|w\|
    \end{equation*}
    Here, $s$ represents the sliding surface, $K$ is a gain matrix, $\eta$ is a 
    positive constant, and $w$ represents disturbance.

    General control optimization can be framed as a Quadratic Programming (QP) 
    problem, aiming to minimize a cost function subject to system dynamics 
    and constraints. The basic form of the optimization problem is as follows:
    \begin{equation}
    \begin{aligned}
    \min_{a_s, \nu} \quad & a_s^T R_a a_s \\
    \textrm{s.t.} \quad & s^TKa_s \geq \eta \|s\| + \|s\|\|w\| \\
    &\hat Ma_s - \hat B\nu = -(\hat{M}a_n + h(r, v))
    \end{aligned}
    \end{equation}

    However, this basic formulation lacks control bounds. 
    To address this, additional constraints are introduced, 
    ensuring that the control inputs remain within feasible bounds:
    \begin{equation}
    \phi_0(u_{min}) \leq \nu \leq \phi_0(u_{max})
    \end{equation}

    Moreover, to alleviate chattering, an uncertainty 
    term $d$ is introduced to the sliding condition. The resulting relaxed 
    sliding condition yields the following optimization problem:
    \begin{equation}
    \begin{aligned}
    \min_{a_s, \nu, d} \quad & a_s^T R_a a_s + \nu^T R_\nu \nu + \gamma^2 d\\
    \textrm{s.t.} \quad & s^TKa_s \geq \eta \|s\| + \|s\|\|w\| + d\\
    &\hat Ma_s - \hat B\nu = -(\hat{M}a_n + h(r, v)) \\
    &\phi_0(u_{min}) \leq \nu \leq \phi_0(u_{max})
    \end{aligned}
    \end{equation}

    Finally, to smooth the control input and reduce abrupt changes, 
    a penalty term is introduced to penalize large deviations between 
    consecutive control inputs:

    \begin{equation}
    \begin{aligned}
    \min_{a_s, \nu, d} \quad & a_s^T R_a a_s + \nu^T R_\nu \nu +
    \gamma_0^2 d + \gamma_1 \|a_s - a_{s (prev)}\|\\
    \textrm{s.t.} \quad & s^TKa_s \geq \eta \|s\| + \|s\|\|w\| + d\\
    &\hat Ma_s - \hat B\nu = -(\hat{M}a_n + h(r, v)) \\
    &\phi_0(u_{min}) \leq \nu \leq \phi_0(u_{max}) \\
    \end{aligned}
    \label{eq::final_opt}
    \end{equation}

    \subsection{Summary}

    Optimization-based control offers a robust framework for addressing complex control 
    problems by leveraging optimization techniques to derive control laws. 
    By formulating control tasks as optimization problems, we can incorporate system 
    dynamics, constraints, and objectives, achieving optimal performance while ensuring 
    robustness and adaptability.
